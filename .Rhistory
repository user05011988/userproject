"positions",
"widths",
"quantification_or_not",
"multiplicities",
"Jcoupling",
"roof_effect",
"shift_tolerance"
)
#Ydata is scaled to improve the quality of the fitting
scaledYdata = as.vector(Ydata / (max(Ydata)))
#Other parameters necessary for the fitting independent of the type of signal
other_fit_parameters$clean_fit = clean_fit
#Adaptation of the info of the parameters into a single matrix and preparation (if necessary) of the background signals that will conform the baseline
FeaturesMatrix = fitting_prep(Xdata,
scaledYdata,
initial_fit_parameters,
other_fit_parameters)
#Depending on the complexity of the ROI, more or less iterations are performed
if (is.numeric(other_fit_parameters$fitting_maxiter)) {
fitting_maxiter = other_fit_parameters$fitting_maxiter
} else {
if (dim(FeaturesMatrix)[1] > 8 |
any(FeaturesMatrix[, 4] - FeaturesMatrix[, 3] > 0.01)) {
fitting_maxiter = 10
} else if ((dim(FeaturesMatrix)[1] > 5 &&
dim(FeaturesMatrix)[1] < 9)) {
fitting_maxiter = 7
} else {
fitting_maxiter = 4
}
}
#Necessary information to incorporate additional singals if necessary
signals_to_quantify = which(FeaturesMatrix[, 11] != 0)
range_ind = round(
other_fit_parameters$additional_signal_ppm_distance / other_fit_parameters$buck_step
)
signals_to_add = other_fit_parameters$signals_to_add
#Variables to initialize the loop
# try_error=000
error2 = 3000
iterrep = 0
fitting_maxiterrep = other_fit_parameters$fitting_maxiterrep
#Function where to find a minimum
residFun <-
function(par, observed, xx,multiplicities,roof_effect,ple)
observed - colSums(fitting_optimization(par, xx,multiplicities,roof_effect,ple))
errorprov = 3000
error1 = 3000
worsterror = 0
# bounds = list(ub = matrix(0, dim(FeaturesMatrix)[1], (dim(FeaturesMatrix)[2] /
#                                                         2) - 2), lb = matrix(0, dim(FeaturesMatrix)[1], (dim(FeaturesMatrix)[2] /
#                                                                                                            2) - 2))
lb = as.vector(t(FeaturesMatrix[, seq(1, 9, 2), drop = F]))
ub = as.vector(t(FeaturesMatrix[, seq(2, 10, 2), drop = F]))
multiplicities=FeaturesMatrix[,11]
roof_effect=FeaturesMatrix[,12]
#Several iterations of the algorith mare performed, to avoid the finding of local optimums that do not represent the best optimization of parameters
s0 = lb + (ub - lb) * runif(length(ub))
if (iterrep %in% seq(1,16,3)) s0[2]=lb[2] + (ub[2] - lb[2]) * runif(1,min=0,max=1/3)
if (iterrep %in% seq(2,17,3)) s0[2]=lb[2] + (ub[2] - lb[2]) * runif(1,min=1/3,max=2/3)
if (iterrep %in% seq(3,18,3)) s0[2]=lb[2] + (ub[2] - lb[2]) * runif(1,min=2/3,max=1)
#
# if (exists('nls.out')) {
#   s0=paramprov+ (ub-lb)*0.2*matrix(runif(dim(lb)[1] * dim(lb)[2],min=-1,max=1), dim(lb)[1], dim(lb)[2])
#   s0[(s0-lb)<0]=lb[(s0-lb)<0]
#   s0[(ub-s0)<0]=ub[(ub-s0)<0]
#
#   }
#
ple=scale(s0)
# print(ple)
s0=scale(s0)
parS=s0
parS
parT=parS*attr(ple,"scaled:scale")+attr(ple,"scaled:center")
parT
load("~/Dolphin/R/shiny_example.RData")
setwd("C:/Users/user/Documents/Dolphin/R")
source('packages_sources.R')
packages_sources()
compiler::enableJIT(3)
#Reading of parameters file
parameters_path = "C:/Users/user/Documents/r_dolphin - csv/Parameters_portuguesos.csv"
parameters_path = "C:/Users/user/Documents/r_dolphin - csv/Parameters_portuguesos_new.csv"
parameters_path = "C:/Users/user/Documents/r_dolphin - csv/Parameters_19_TSP_improved.csv"
parameters_path = "C:/Users/user/Documents/r_dolphin - csv/Parameters_binning_dataset.csv"
parameters_path = "C:/Users/user/Documents/r_dolphin - csv/Parameters_csv.csv"
parameters_path = "C:/Users/user/Documents/r_dolphin - csv/Parameters_binning_dataset_new.txt"
parameters_path = "C:/Bruker/TopSpin3.2/data/MTBLS1/data analysis/Parameters_20_2.csv"
parameters_path = "C:/Bruker/TopSpin3.2/data/MTBLS1/data analysis/Parameters.csv"
#import of data (dataset in csv format or Bruker nmr folder)
imported_data = import_data(parameters_path)
ROI_data = read.csv(autorun_data$profile_folder_path, sep = ",",stringsAsFactors = F)
ROI_data = read.csv(autorun_data$profile_folder_path, sep = ",",stringsAsFactors = F)[,-1]
write.csv(ROI_data,autorun_data$profile_folder_path,row.names=F,sep=';')
?write.csv
write.csv(ROI_data,autorun_data$profile_folder_path,row.names=F)
setwd("C:/Users/user/Documents/Dolphin/R")
source('packages_sources.R')
packages_sources()
compiler::enableJIT(3)
#Reading of parameters file
parameters_path = "C:/Users/user/Documents/r_dolphin - csv/Parameters_portuguesos.csv"
parameters_path = "C:/Users/user/Documents/r_dolphin - csv/Parameters_portuguesos_new.csv"
parameters_path = "C:/Users/user/Documents/r_dolphin - csv/Parameters_19_TSP_improved.csv"
parameters_path = "C:/Users/user/Documents/r_dolphin - csv/Parameters_binning_dataset.csv"
parameters_path = "C:/Users/user/Documents/r_dolphin - csv/Parameters_csv.csv"
parameters_path = "C:/Users/user/Documents/r_dolphin - csv/Parameters_binning_dataset_new.txt"
parameters_path = "C:/Bruker/TopSpin3.2/data/MTBLS1/data analysis/Parameters_20_2.csv"
parameters_path = "C:/Bruker/TopSpin3.2/data/MTBLS1/data analysis/Parameters.csv"
#import of data (dataset in csv format or Bruker nmr folder)
imported_data = import_data(parameters_path)
if (!dir.exists(imported_data$export_path))
dir.create(imported_data$export_path)
for (i in seq_along(imported_data$Experiments)) {
if (!dir.exists(file.path(imported_data$export_path, imported_data$Experiments[i]))) {
dir.create(file.path(imported_data$export_path, imported_data$Experiments[i]))
}
}
#
params = list()
#Import fo parameters from the csv file
# TO DO: stringsasfactors=F
import_profile = read.delim(
parameters_path,
sep = ',',
header = T,
stringsAsFactors = F
)
import_profile = as.data.frame(sapply(import_profile, function(x)
gsub("\\\\", "/", x)))
metadata_path = as.character(import_profile[3, 2])
dummy = read.delim(
metadata_path,
sep = ',',
header = T,
stringsAsFactors = F
)
Experiments=dummy[,1]
Experiments = as.vector(Experiments[Experiments != ''])
Metadata=dummy[,-1,drop=F]
profile_folder_path = as.character(import_profile[7, 2])
ROI_data=read.csv(profile_folder_path)
signals_names=ROI_data[,4]
signals_codes = 1:length(signals_names)
#Preparing the structure of experiments and signals where to store the output
export_path = as.character(import_profile[8, 2])
#Criteria for saving or not plots of fit
E_max = as.numeric(as.character(import_profile[9, 2]))
P_max = as.numeric(as.character(import_profile[10, 2]))
#Other necessary variables
freq = as.numeric(as.character(import_profile[14, 2]))
#Kind of normalization
#TO DO: add PQN (but before standardize a way to find the regions to have into account)
normalization = import_profile[11, 2]
params$norm_AREA = 'N'
params$norm_PEAK = 'N'
params$norm_left_ppm = 12
params$norm_right_ppm = -1
if (normalization == 1) {
#Eretic
params$norm_AREA = 'Y'
params$norm_left_ppm = 11.53
params$norm_right_ppm = 10.47
} else if (normalization == 2) {
#TSP
params$norm_AREA = 'Y'
params$norm_left_ppm = 0.1
params$norm_right_ppm = -0.1
} else if (normalization == 3) {
#Creatinine (intensity, not area, maybe dangerous for rats because of oxalacetate)
params$norm_PEAK = 'Y'
params$norm_left_ppm = 3.10
params$norm_right_ppm = 3
} else if (normalization == 4) {
#Spectrum AreA
params$norm_AREA = 'Y'
} else if (normalization == 5) {
#No normailzation
} else if (normalization == 6) {
#No normailzation
params$norm_AREA = 'Y'
pqn='Y'
}
alignment = import_profile[12, 2]
params$glucose_alignment = 'N'
params$tsp_alignment = 'N'
params$peak_alignment = 'N'
params$ref_pos = 8.452
if (alignment == 1) {
#Glucose
params$glucose_alignment = 'Y'
} else if (alignment == 2) {
#TSP
params$tsp_alignment = 'Y'
} else if (alignment == 3) {
#Formate
params$peak_alignment = 'Y'
}
#Suppresion regions
suppression = as.character(import_profile[13, 2])
if (suppression == '') {
params$disol_suppression = 'N'
} else {
params$disol_suppression = 'Y'
params$disol_suppression_ppm = as.numeric(strsplit(suppression, '-|,')[[1]])
dim(params$disol_suppression_ppm) = c(length(params$disol_suppression_ppm) /
2, 2)
params$disol_suppression_ppm = t(params$disol_suppression_ppm)
}
#Variables only necessary for reading Bruker files
bruker_path = import_profile[1, 2]
expno = as.character(import_profile[4, 2])
processingno = as.character(import_profile[5, 2])
#Variables only necessary for reading dataset in csv format
dataset_path = as.character(import_profile[2, 2])
setwd("C:/Users/user/Documents/Dolphin/R")
source('packages_sources.R')
packages_sources()
compiler::enableJIT(3)
#Reading of parameters file
parameters_path = "C:/Users/user/Documents/r_dolphin - csv/Parameters_portuguesos.csv"
parameters_path = "C:/Users/user/Documents/r_dolphin - csv/Parameters_portuguesos_new.csv"
parameters_path = "C:/Users/user/Documents/r_dolphin - csv/Parameters_19_TSP_improved.csv"
parameters_path = "C:/Users/user/Documents/r_dolphin - csv/Parameters_binning_dataset.csv"
parameters_path = "C:/Users/user/Documents/r_dolphin - csv/Parameters_csv.csv"
parameters_path = "C:/Users/user/Documents/r_dolphin - csv/Parameters_binning_dataset_new.txt"
parameters_path = "C:/Bruker/TopSpin3.2/data/MTBLS1/data analysis/Parameters_20_2.csv"
parameters_path = "C:/Bruker/TopSpin3.2/data/MTBLS1/data analysis/Parameters.csv"
#import of data (dataset in csv format or Bruker nmr folder)
imported_data = import_data(parameters_path)
if (!dir.exists(imported_data$export_path))
dir.create(imported_data$export_path)
for (i in seq_along(imported_data$Experiments)) {
if (!dir.exists(file.path(imported_data$export_path, imported_data$Experiments[i]))) {
dir.create(file.path(imported_data$export_path, imported_data$Experiments[i]))
}
}
#creation of list with the different final outputs
finaloutput = list()
dummy = matrix(NaN,
dim(imported_data$dataset)[1],
length(imported_data$signals_names))
rownames(dummy) = imported_data$Experiments
colnames(dummy) = imported_data$signals_names
finaloutput$Area = finaloutput$signal_area_ratio = finaloutput$fitting_error =
finaloutput$shift = finaloutput$intensity = finaloutput$width = dummy
write.csv(
as.data.frame(imported_data$params),
file.path(imported_data$export_path, 'initialparams.csv'),
row.names = F
)
colnames(imported_data$dataset) = imported_data$ppm
rownames(imported_data$dataset) = imported_data$Experiments
write.csv(imported_data$dataset,
file.path(imported_data$export_path, 'initialdataset.csv'))
if ("not_loaded_experiments" %in% names(imported_data))
write.table(
imported_data$not_loaded_experiments,
file.path(imported_data$export_path, 'not_loaded_experiments.csv'),
row.names = F,
col.names = F
)
# write.table(
#   t(as.data.frame(imported_data$signals_names)),
#   file.path(imported_data$export_path, 'used_library.csv'),
#   row.names = F,
#   col.names = F
# )
#creation of a folder for every experiment
# for (i in seq_along(imported_data$Experiments))
#   if (!dir.exists(file.path(export_path, imported_data$Experiments[i])))
#     dir.create(file.path(export_path, imported_data$Experiments[i]))
autorun_data = list(
dataset = imported_data$dataset,
ppm = imported_data$ppm,
buck_step = imported_data$buck_step,
profile_folder_path = imported_data$profile_folder_path,
signals_names = imported_data$signals_names,
signals_codes = imported_data$signals_codes,
Experiments = imported_data$Experiments,
export_path = imported_data$export_path,
freq = imported_data$freq,
Metadata=imported_data$Metadata
)
rm(imported_data)
finaloutput = autorun(autorun_data, finaloutput)
setwd("C:/Users/user/Documents/Dolphin/R")
source('packages_sources.R')
packages_sources()
compiler::enableJIT(3)
autorun_data = list(
dataset = imported_data$dataset,
ppm = imported_data$ppm,
buck_step = imported_data$buck_step,
profile_folder_path = imported_data$profile_folder_path,
signals_names = imported_data$signals_names,
signals_codes = imported_data$signals_codes,
Experiments = imported_data$Experiments,
export_path = imported_data$export_path,
freq = imported_data$freq,
Metadata=imported_data$Metadata
)
rm(imported_data)
finaloutput = autorun(autorun_data, finaloutput)
setwd("C:/Users/user/Documents/Dolphin/R")
source('packages_sources.R')
packages_sources()
compiler::enableJIT(3)
finaloutput = autorun(autorun_data, finaloutput)
ROI_data = read.csv(autorun_data$profile_folder_path, stringsAsFactors = F)
dummy = which(!is.na(ROI_data[, 1]))
ROI_separator = cbind(dummy, c(dummy[-1] - 1, dim(ROI_data)[1]))
ROI_index=1
pre_import_excel_profile = ROI_data[ROI_separator[ROI_index, 1]:ROI_separator[ROI_index, 2],]
ROI_limits = round(as.numeric(pre_import_excel_profile[1, 1:2]),3)
if (ROI_limits[1] < ROI_limits[2])
rev(ROI_limits)
print(paste(ROI_limits[1], ROI_limits[2], sep = '-'))
ROI_buckets = which(autorun_data$ppm <= ROI_limits[1] &
autorun_data$ppm >=
ROI_limits[2])
preXdata = autorun_data$ppm[ROI_buckets]
pre_import_excel_profile
finaloutput = autorun(autorun_data, finaloutput)
ROI_data = read.csv(autorun_data$profile_folder_path, stringsAsFactors = F)
dummy = which(!is.na(ROI_data[, 1]))
ROI_separator = cbind(dummy, c(dummy[-1] - 1, dim(ROI_data)[1]))
# mtcars2=ROI_data[1:2,4:11]
# mtcars=ROI_data[1:2,4:11]
ROI_names=paste(ROI_data[ROI_separator[, 1],1],ROI_data[ROI_separator[, 1],2])
select_options=1:length(ROI_names)
names(select_options)=ROI_names
t_test_data=autorun_data$dataset
ss=unique(autorun_data$Metadata[,1])
tt=matrix(NA,length(ss),dim(t_test_data)[2])
for (ind in seq_along(ss)) {
for (k in 1.:dim(t_test_data)[2]) {
tt[ind,k]=tryCatch(shapiro.test(t_test_data[autorun_data$Metadata[,1]==ss[ind],k])$p.value,error=function(e) NA)
}
}
p_value_bucketing=rep(NA,dim(t_test_data)[2])
for (k in 1:dim(t_test_data)[2]) {
# if (!any(is.na(t_test_data[,k]))) {
if (!any(tt[,k]<0.05,na.rm=T)) {
p_value_bucketing[k]=tryCatch(wilcox.test(t_test_data[autorun_data$Metadata[,1]==ss[1],k],t_test_data[autorun_data$Metadata[,1]==ss[2],k])$p.value,error=function(e) NA)
} else {
p_value_bucketing[k]=tryCatch(t.test(t_test_data[autorun_data$Metadata[,1]==ss[1],k],t_test_data[autorun_data$Metadata[,1]==ss[2],k],var.equal=F)$p.value,error=function(e) NA)
}
# }
}
p_value_bucketing[is.na(p_value_bucketing)]=0
plotdata = data.frame(Xdata=autorun_data$ppm, p_value_bucketing)
mediani=apply(autorun_data$dataset,2,function(x) median(x,na.rm=T))
# plot_ly(data=plotdata,x=~Xdata,y=~Ydata)
bucketing <- cbind(melt(plotdata, id = "Xdata"),mediani)
plot_ly(data=bucketing,x=~Xdata,y=~mediani,color=~value,type='scatter',mode='lines') %>% layout(xaxis = list(autorange = "reversed"),yaxis = list(range = c(0, max(mediani))))
t_test_data_2=finaloutput$Area
t_test_data_2[finaloutput$fitting_error>other_fit_parameters$fitting_error_limit]=NA
t_test_data_2[finaloutput$signal_area_ratio<other_fit_parameters$signal_area_ratio_limit]=NA
ll=as.data.frame(t_test_data_2)
Xwit=cbind(ll,factor(autorun_data$Metadata[,1]))
# rownames(Xwit)=NULL
ab=melt(Xwit)
colnames(ab)=c('Metadata','Signal','Value')
outlier_table=matrix(0,dim(ll)[1],dim(ll)[2])
colnames(outlier_table)=colnames(t_test_data_2)
rownames(outlier_table)=rownames(finaloutput$fitting_error)
for (i in 1:dim(ll)[2]) {
for (j in length(ss)) {
outliers=boxplot.stats(ll[autorun_data$Metadata==ss[j],i])$out
outlier_table[ll[autorun_data$Metadata==ss[j],i] %in%  outliers]=1
}}
ss=unique(autorun_data$Metadata[,1])
tt=matrix(NA,length(ss),dim(t_test_data_2)[2])
for (ind in seq_along(ss)) {
for (k in 1:dim(t_test_data_2)[2]) {
tt[ind,k]=tryCatch(shapiro.test(t_test_data_2[autorun_data$Metadata[,1]==ss[ind],k])$p.value,error=function(e) NA)
}
}
p_value=rep(NA,dim(t_test_data_2)[2])
for (k in 1:dim(t_test_data_2)[2]) {
# if (!any(is.na(t_test_data_2[,k]))) {
if (!any(tt[,k]<0.05,na.rm=T)) {
p_value[k]=tryCatch(wilcox.test(t_test_data_2[autorun_data$Metadata[,1]==ss[1],k],t_test_data_2[autorun_data$Metadata[,1]==ss[2],k])$p.value,error=function(e) NA)
} else {
p_value[k]=tryCatch(t.test(t_test_data_2[autorun_data$Metadata[,1]==ss[1],k],t_test_data_2[autorun_data$Metadata[,1]==ss[2],k],var.equal=F)$p.value,error=function(e) NA)
}
# }
}
p_value_final=t(as.matrix(p_value))
colnames(p_value_final)=colnames(t_test_data_2)
other_fit_parameters = fitting_variables()
t_test_data_2=finaloutput$Area
t_test_data_2[finaloutput$fitting_error>other_fit_parameters$fitting_error_limit]=NA
t_test_data_2[finaloutput$signal_area_ratio<other_fit_parameters$signal_area_ratio_limit]=NA
ll=as.data.frame(t_test_data_2)
Xwit=cbind(ll,factor(autorun_data$Metadata[,1]))
# rownames(Xwit)=NULL
ab=melt(Xwit)
colnames(ab)=c('Metadata','Signal','Value')
outlier_table=matrix(0,dim(ll)[1],dim(ll)[2])
colnames(outlier_table)=colnames(t_test_data_2)
rownames(outlier_table)=rownames(finaloutput$fitting_error)
for (i in 1:dim(ll)[2]) {
for (j in length(ss)) {
outliers=boxplot.stats(ll[autorun_data$Metadata==ss[j],i])$out
outlier_table[ll[autorun_data$Metadata==ss[j],i] %in%  outliers]=1
}}
ss=unique(autorun_data$Metadata[,1])
tt=matrix(NA,length(ss),dim(t_test_data_2)[2])
for (ind in seq_along(ss)) {
for (k in 1:dim(t_test_data_2)[2]) {
tt[ind,k]=tryCatch(shapiro.test(t_test_data_2[autorun_data$Metadata[,1]==ss[ind],k])$p.value,error=function(e) NA)
}
}
p_value=rep(NA,dim(t_test_data_2)[2])
for (k in 1:dim(t_test_data_2)[2]) {
# if (!any(is.na(t_test_data_2[,k]))) {
if (!any(tt[,k]<0.05,na.rm=T)) {
p_value[k]=tryCatch(wilcox.test(t_test_data_2[autorun_data$Metadata[,1]==ss[1],k],t_test_data_2[autorun_data$Metadata[,1]==ss[2],k])$p.value,error=function(e) NA)
} else {
p_value[k]=tryCatch(t.test(t_test_data_2[autorun_data$Metadata[,1]==ss[1],k],t_test_data_2[autorun_data$Metadata[,1]==ss[2],k],var.equal=F)$p.value,error=function(e) NA)
}
# }
}
p_value_final=t(as.matrix(p_value))
colnames(p_value_final)=colnames(t_test_data_2)
p_value_final
save.image("C:/Users/user/Downloads/interface_example.RData")
print(source('prova.R')$value)
print(source('prova.R')$value)
print(source('prova.R')$value)
print(source('prova.R')$value)
print(source('prova.R')$value)
print(source('prova.R')$value)
print(source('prova.R')$value)
print(source('prova.R')$value)
print(source('prova.R')$value)
print(source('prova.R')$value)
print(source('prova.R')$value)
print(source('prova.R')$value)
print(source('prova.R')$value)
print(source('prova.R')$value)
print(source('prova.R')$value)
print(source('prova.R')$value)
print(source('prova.R')$value)
print(source('prova.R')$value)
ROI_profile=import(file.path(path,'import_excel_profile.csv'))[,-1,drop=F]
path=paste(autorun_data$export_path,autorun_data$Experiments[sell$info$row],autorun_data$signals_names[sell$info$col],sep='/')
ROI_separator
ind=which(ROI_data[,3]==autorun_data$signals_names[3])
ind
ROI_data[,3]
ROI_data[,4]
ind=which(ROI_data[,4]==autorun_data$signals_names[sell$info$col])
ind=which(ROI_data[,3]==autorun_data$signals_names[4])
ind
ind=which(ROI_data[,4]==autorun_data$signals_names[3])
ind
ROI_separator
ROI_separator[, 1]>=sol
sol=which(ROI_data[,4]==autorun_data$signals_names[3])
ROI_separator[, 1]>=sol
ROI_separator[, 1]<sol
ROI_separator[, 1]<sol+1
ROI_separator[, 1]<=sol
which(ROI_separator[, 1]>=sol&ROI_separator[, 1]<=sol)
ROI_separator[, 1][ind]
print(source('prova.R')$value)
print(source('prova.R')$value)
print(source('prova.R')$value)
print(source('prova.R')$value)
print(source('prova.R')$value)
print(source('prova.R')$value)
print(source('prova.R')$value)
print(source('prova.R')$value)
print(source('prova.R')$value)
load("~/Dolphin/R/man.RData")
load("C:/Users/user/Downloads/interface_example.RData")
load("~/Dolphin/R/ff.RData")
View(bucketing)
?wilcox.test
load("~/Dolphin/R/man.RData")
sell<-trek
rm(trek)
save.image("~/Dolphin/R/.RData")
load("~/Dolphin/R/shiny_env.Rdata")
load("C:/Bruker/TopSpin3.2/data/MTBLS1/data analysis/results_csv_132/savedenvironment.Rdata")
b=list()
b=elements
b(:)=elements(:)
b()=elements()
b[]=elements[]
b[[]]=elements[[]]
unlist(elements)
ll=unlist(elements)
plo=names(sapply(elements, names))
load("~/Dolphin/R/shiny_env.Rdata")
sell[[plo]]
sell[['brks']]
plo[1]
plo
plo=names(sapply(elements, names))
plo
plo[1]
sell[[plo]]
elements[plo[1]]
elements$finaloutput
b[[c('brks','crls')]]=elements[[c('brks','crls')]]
b[c('brks','crls')]]=elements[c('brks','crls')]]
b[c('brks','crls')]=elements[c('brks','crls')]
